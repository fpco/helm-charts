  groups:
  - name: fpco.rules
    rules:
    - alert: NodeCPUUsage
      expr: (100 - (avg by (instance) (irate(node_cpu{name="node-exporter",mode="idle"}[5m])) * 100)) > 75
      for: 2m
      labels:
        severity: page
      annotations:
        summary: "{{$labels.instance}}: High CPU usage detected"
        description: "{{$labels.instance}}: CPU usage is above 75% (current value is: {{ $value }})"
    - alert: NodeSwapUsage
      expr: (((node_memory_SwapTotal-node_memory_SwapFree)/node_memory_SwapTotal)*100) > 75
      for: 2m
      labels:
        severity: page
      annotations:
        summary: "{{$labels.instance}}: Swap usage detected"
        description: "{{$labels.instance}}: Swap usage usage is above 75% (current value is: {{ $value }})"
    - alert: NodeMemoryUsage
      expr: (((node_memory_MemTotal-node_memory_MemFree-node_memory_Cached)/(node_memory_MemTotal)*100)) > 75
      for: 2m
      labels:
        severity: page
      annotations:
        summary: "{{$labels.instance}}: High memory usage detected"
        description: "{{$labels.instance}}: Memory usage is above 75% (current value is: {{ $value }})"
    - alert: NodeLowRootDisk
      expr: ((node_filesystem_size{mountpoint="/"} - node_filesystem_free{mountpoint="/"} ) / node_filesystem_size{mountpoint="/"} * 100) > 75
      for: 2m
      labels:
        severity: page
      annotations:
        summary: "{{$labels.instance}}: Low root disk space"
        description: "{{$labels.instance}}: Root disk usage is above 75% (current value is: {{ $value }})"
    - alert: NodeLoadAverage
      expr: ((node_load5 / count without (cpu, mode) (node_cpu{mode="system"})) > 1)
      for: 2m
      labels:
        severity: page
      annotations:
        summary: "{{$labels.instance}}: High Load Average detected"
        description: "{{$labels.instance}}: Load average is high"
    - alert: KubePodCrashLooping
      annotations:
        message: Pod {{ $labels.namespace }}/{{ $labels.pod }} ({{ $labels.container
          }}) is restarting {{ printf "%.2f" $value }} times / 3 minutes.
        summary: "Pod {{ $labels.namespace }}/{{ $labels.pod }} is restarting too much!"
        description: Pod {{ $labels.namespace }}/{{ $labels.pod }} ({{ $labels.container }}) is restarting {{ printf "%.2f" $value }} times / 5 minutes.
      expr: |
        rate(kube_pod_container_status_restarts_total[15m]) * 60 * 3 > 0
      for: 5m
      labels:
        severity: critical
    - alert: KubePodNotReady
      annotations:
        message: "Pod {{ $labels.namespace }}/{{ $labels.pod }} has been in a non-ready state for longer than an hour."
        summary: "Pod {{ $labels.namespace }}/{{ $labels.pod }} is not ready."
        description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} has been in a non-ready state for longer than an hour."
      expr: |
        sum by (namespace, pod) (kube_pod_status_phase{phase=~"Pending|Unknown"}) > 0
      for: 1h
      labels:
        severity: critical
    - alert: KubeAPIDown
      annotations:
        message: "KubeAPI has disappeared from Prometheus target discovery."
      expr: |
        absent(up{job="apiserver"} == 1)
      for: 15m
      labels:
        severity: critical
    - alert: KubeControllerManagerDown
      annotations:
        message: "KubeControllerManager has disappeared from Prometheus target discovery."
      expr: |
        absent(up{job="kube-controller-manager"} == 1)
      for: 15m
      labels:
        severity: critical
    - alert: KubeSchedulerDown
      annotations:
        message: "KubeScheduler has disappeared from Prometheus target discovery."
      expr: |
        absent(up{job="kube-scheduler"} == 1)
      for: 15m
      labels:
        severity: critical
    - alert: KubeletDown
      annotations:
        message: "Kubelet has disappeared from Prometheus target discovery."
      expr: |
        absent(up{job="kubelet"} == 1)
      for: "15m"
      labels:
        severity: critical
